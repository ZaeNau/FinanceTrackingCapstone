{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Receipt Object Detection [CH2-PS579]\n",
        "\n",
        "\n",
        "*   Muhammad Aditya Hasta Pratama (M299BSY0188) - ML - Universitas Pendidikan Indonesia / Active\n",
        "*   Shereva Miranda (M002BSX0590) - ML - Institut Teknologi Bandung / Active\n",
        "*   Reza Nugraha (M002BSY1855) - ML - Institut Teknologi Bandung / Inactive\n",
        "\n",
        "</br>\n",
        "\n",
        "Reference Tutorial :     \n",
        "\n",
        "*   [Tensorflow 2 Custom Object Detection Model by Lazy Tech](https://www.youtube.com/watch?v=8ktcGQ-XreQ&t=553s&ab_channel=LazyTech).\n",
        "*   [Train a Deep Learning Model for Custom Object Detection Using TensorFlow by TechZizou](https://www.youtube.com/watch?v=amURyS6CAaY&t=69s&ab_channel=techzizou)\n"
      ],
      "metadata": {
        "id": "L9b-rde54YmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) PREPARATION\n",
        "\n",
        "Library and installation that are needed for running the architecture."
      ],
      "metadata": {
        "id": "kUGBQcZaHnOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install tensorFlow 2.13.0\n",
        "!pip install tensorflow==\"2.13.0\""
      ],
      "metadata": {
        "id": "xKtipLaT7IgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import pathlib"
      ],
      "metadata": {
        "id": "5tLvXo-h3H_8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download models for object detection\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "id": "DmvPDG-O9sDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the object detection API\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "metadata": {
        "id": "J2ZNn-CiIZVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing model builder\n",
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "id": "8-k1am-FJOdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) DONWLOAD DATASET (KAGGLE)\n",
        "\n",
        "Preparing receipt dataset, tfrecords, and labelmap from kaggle.\n",
        "\n",
        "Link = https://www.kaggle.com/datasets/mdhstama23/receipt-invoice-ml-ch2ps357\n",
        "\n",
        "*note: we forgot our number team so the link kaggle is different from acctually*"
      ],
      "metadata": {
        "id": "S0685ws1JZ4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install kaggle API\n",
        "!pip install -q kaggle\n",
        "!pip install -q kaggle-cli"
      ],
      "metadata": {
        "id": "eIljRoWnJr9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get yours username and key kaggle API, makes sure you have a kaggle account.\n",
        "\n",
        "If you have already created a kaggle account or previously had a kaggle account, please follow these steps:\n",
        "\n",
        "\n",
        "1.   Go to your **ACCOUNT SETTINGS**\n",
        "2.   Click on **CREATE NEW TOKEN**, it will be automically download the kaggle.json file\n",
        "3.   Open the .json files and extract the username and key. Use the obtained values in the code below\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f-LeC8mhJjAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting environtment for kaggle API\n",
        "# Change the username or the key to match yours\n",
        "username = \"mdhstama23\"\n",
        "key = \"f084d767ac2346b9cc7ca59718be801b\"\n",
        "os.environ['KAGGLE_USERNAME'] = username\n",
        "os.environ['KAGGLE_KEY'] = key"
      ],
      "metadata": {
        "id": "uHsGtWwbJ0OS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "!kaggle datasets download -d mdhstama23/receipt-invoice-ml-ch2ps357 --unzip\n",
        "!ls"
      ],
      "metadata": {
        "id": "gmwP9xeqK5c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) CONFIGURE THE DATASET\n",
        "\n",
        "Preparing the csv and record files for training the model."
      ],
      "metadata": {
        "id": "7JXTfE4x8jMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the images labels for dataset\n",
        "\n",
        "# go to the directory\n",
        "%cd /content/dataset/data/\n",
        "\n",
        "# Create new folder for split labels\n",
        "!mkdir test_labels train_labels\n",
        "\n",
        "# Lists the files inside 'annotations' in a random order\n",
        "# Moves the 100/500 labels (20% of the labels) to the testing directory `test_labels`\n",
        "!ls annotations/* | sort -R | head -100 | xargs -I{} mv {} test_labels/\n",
        "\n",
        "# Moves the rest (400 labels) of the labels (80% of the labels ) to the training directory `train_labels`\n",
        "!ls annotations/* | xargs -I{} mv {} train_labels/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0S0kiXD8r_u",
        "outputId": "2724a122-5dbd-4f59-87b1-2225a80574e0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CSV files from the XML labels and the label_map.pbtxt files\n",
        "\n",
        "def xml_to_csv(path):\n",
        "    # Lists to store class names and XML data\n",
        "    classes_names = []\n",
        "    xml_list = []\n",
        "\n",
        "    # Loop through each XML file in the specified path\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        # Parse the XML file\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        # Loop through each 'object' element in the XML\n",
        "        for member in root.findall('object'):\n",
        "            # Add class name to the list\n",
        "            classes_names.append(member[0].text)\n",
        "\n",
        "            # Extract relevant information and create a tuple\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member[4][0].text),\n",
        "                     int(member[4][1].text),\n",
        "                     int(member[4][2].text),\n",
        "                     int(member[4][3].text))\n",
        "\n",
        "            # Add the tuple to the XML data list\n",
        "            xml_list.append(value)\n",
        "\n",
        "    # Define column names for the DataFrame\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "\n",
        "    # Create a DataFrame from the XML data\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "\n",
        "    # Remove duplicate class names, sort, and store in 'classes_names'\n",
        "    classes_names = list(set(classes_names))\n",
        "    classes_names.sort()\n",
        "\n",
        "    # Return the DataFrame and the list of unique class names\n",
        "    return xml_df, classes_names\n",
        "\n",
        "# Process both 'train_labels' and 'test_labels' directories\n",
        "for label_path in ['train_labels', 'test_labels']:\n",
        "    # Construct the full path to the label directory\n",
        "    image_path = os.path.join(os.getcwd(), label_path)\n",
        "\n",
        "    # Call the xml_to_csv function to convert XML to CSV\n",
        "    xml_df, classes = xml_to_csv(label_path)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    xml_df.to_csv(f'{label_path}.csv', index=None)\n",
        "\n",
        "    # Print success message\n",
        "    print(f'Successfully converted {label_path} xml to csv.')\n",
        "\n",
        "# Create the label_map.pbtxt file\n",
        "label_map_path = os.path.join(\"label_map.pbtxt\")\n",
        "pbtxt_content = \"\"\n",
        "\n",
        "# Loop through each class and format the content for label_map.pbtxt\n",
        "for i, class_name in enumerate(classes):\n",
        "    pbtxt_content = (\n",
        "        pbtxt_content\n",
        "        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(i + 1, class_name)\n",
        "    )\n",
        "\n",
        "# Remove trailing whitespace and write content to label_map.pbtxt\n",
        "pbtxt_content = pbtxt_content.strip()\n",
        "with open(label_map_path, \"w\") as f:\n",
        "    f.write(pbtxt_content)\n",
        "    print('Successfully created label_map.pbtxt ')"
      ],
      "metadata": {
        "id": "NnOiBrJy-GSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create test and train.record files\n",
        "\n",
        "#For train.record\n",
        "!python /content/dataset/generate_tfrecord.py train_labels.csv  label_map.pbtxt images/ train.record\n",
        "\n",
        "#For test.record\n",
        "!python /content/dataset/generate_tfrecord.py test_labels.csv  label_map.pbtxt images/ test.record"
      ],
      "metadata": {
        "id": "vAfreo6pAf9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) ARCHITECTURE OR MODEL CONFIGURATION\n",
        "\n",
        "Configuration training model with model that avaiable in [Tensorflow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)."
      ],
      "metadata": {
        "id": "jE89RKrzLh4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization\n",
        "num_classes = 1\n",
        "fine_tune_checkpoint_type = 'detection'\n",
        "batch_size = 64\n",
        "num_steps = 1000\n",
        "num_eval_steps = 1000"
      ],
      "metadata": {
        "id": "Xr2KuPHCMaWI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the architecture\n",
        "\n",
        "# Move the directory\n",
        "%cd /content/dataset/data\n",
        "\n",
        "# Change this link and name if you want to train with another model\n",
        "link_model = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\"\n",
        "name_model = \"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\"\n",
        "\n",
        "# download the model\n",
        "!wget {link_model}\n",
        "!tar -xf {name_model}"
      ],
      "metadata": {
        "id": "Y-CUUtfrNHsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the config file\n",
        "\n",
        "# Change this link config based on your preferred model before\n",
        "config_link = \"https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_mobilenet_v2_320x320_coco17_tpu-8.config\"\n",
        "\n",
        "# Download the model\n",
        "!wget {config_link}"
      ],
      "metadata": {
        "id": "1WWo5XR7PohN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b2902d-175a-4f12-d497-35b74d968c80"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-21 07:29:36--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_mobilenet_v2_320x320_coco17_tpu-8.config\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4484 (4.4K) [text/plain]\n",
            "Saving to: ‘ssd_mobilenet_v2_320x320_coco17_tpu-8.config’\n",
            "\n",
            "ssd_mobilenet_v2_32 100%[===================>]   4.38K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-21 07:29:36 (31.2 MB/s) - ‘ssd_mobilenet_v2_320x320_coco17_tpu-8.config’ saved [4484/4484]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change this link based on your preferred model before\n",
        "fine_tune_checkpoint = '/content/dataset/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0'\n",
        "base_config_path = '/content/ssd_mobilenet_v2_320x320_coco17_tpu-8.config'\n",
        "\n",
        "# Path initialization\n",
        "train_record_path = '/content/dataset/data/train.record'\n",
        "test_record_path = '/content/dataset/data/test.record'\n",
        "labelmap_path = '/content/dataset/data/label_map.pbtxt'"
      ],
      "metadata": {
        "id": "fwoUt07YEFlh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Edit the config file\n",
        "\n",
        "import re\n",
        "\n",
        "with open(base_config_path) as f:\n",
        "    config = f.read()\n",
        "\n",
        "with open('model_config.config', 'w') as f:\n",
        "\n",
        "  # Set number of classes.\n",
        "  config = re.sub('num_classes: [0-9]+',\n",
        "                  'num_classes: {}'.format(num_classes), config)\n",
        "\n",
        "  # Set fine_tune_checkpoint path\n",
        "  config = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "                  'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), config)\n",
        "\n",
        "  # Set fine-tune checkpoint type to detection\n",
        "  config = re.sub('fine_tune_checkpoint_type: \"classification\"',\n",
        "             'fine_tune_checkpoint_type: \"{}\"'.format('detection'), config)\n",
        "\n",
        "  # Set batch size\n",
        "  config = re.sub('batch_size: [0-9]+',\n",
        "                  'batch_size: {}'.format(batch_size), config)\n",
        "\n",
        "  # Set training steps\n",
        "  config = re.sub('num_steps: [0-9]+',\n",
        "                  'num_steps: {}'.format(num_steps), config)\n",
        "\n",
        "  # Set labelmap path\n",
        "  config = re.sub('label_map_path: \".*?\"',\n",
        "             'label_map_path: \"{}\"'.format(labelmap_path), config)\n",
        "\n",
        "  # Set train tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")',\n",
        "                  'input_path: \"{}\"'.format(train_record_path), config)\n",
        "\n",
        "  # Set test tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")',\n",
        "                  'input_path: \"{}\"'.format(test_record_path), config)\n",
        "\n",
        "  f.write(config)"
      ],
      "metadata": {
        "id": "nlXmvYRcTfrl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tensorboard\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/dataset/training'"
      ],
      "metadata": {
        "id": "0WcF7y14El53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) TRAINING THE MODEL\n",
        "\n",
        "Traiing the model based the architecture configuration before"
      ],
      "metadata": {
        "id": "2RcQ2Nq2XbXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization\n",
        "\n",
        "model_dir = '/content/dataset/data/train_history'\n",
        "pipeline_config_path = '/content/dataset/data/model_config.config'"
      ],
      "metadata": {
        "id": "SlTUefrgXwfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the model\n",
        "\n",
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_config_path} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "metadata": {
        "id": "A69hMclvX2Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6) ERROR ENCOUNTERED\n",
        "\n",
        "If you encountered an error like this\n",
        "\n",
        "\"Tensorflow: AttributeError: module 'tensorflow.python.ops.control_flow_ops' has no attribute 'case'\"\n",
        "\n",
        "Please run again the tensorflow installation above and ignore it if the collab tells you to restart the session.\n",
        "\n",
        "Then run it again the steps 5.\n",
        "\n",
        "```\n",
        "!pip install tensorflow==\"2.13.0\"\n",
        "```"
      ],
      "metadata": {
        "id": "Fd-wDq7NL9iu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7) RETRAINING THE MODEL (IN CASE BECAUSE LIMITIATION OF COLLABS OR DISCONNECT)\n",
        "\n",
        "If you expereience error because collab limitation or disconnect, you can run this code and run again the step 5.\n",
        "\n",
        "However, change the number of checkpoint. You can check the number inside folder of train_history.\n",
        "\n",
        "The model_main_tf2.py script saves the checkpoint every 1000 steps. The training automatically restarts from the last saved checkpoint itself.\n"
      ],
      "metadata": {
        "id": "fdVGdeGhGUJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Edit this number based on the checkpoint number\n",
        "number_checkpoint = 1\n",
        "\n",
        "# Path initialization\n",
        "new_base_config_path = '/content/dataset/data/model_config.config'\n",
        "new_fine_tune_checkpoint = f'/content/dataset/data/train_history/ckpt-{number_checkpoint}'\n",
        "\n",
        "# Edit the config file\n",
        "import re\n",
        "\n",
        "with open(new_base_config_path) as f:\n",
        "    config = f.read()\n",
        "\n",
        "with open('model_config.config', 'w') as f:\n",
        "\n",
        "    # Set fine_tune_checkpoint path\n",
        "    config = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "                    'fine_tune_checkpoint: \"{}\"'.format(new_fine_tune_checkpoint), config)\n",
        "\n",
        "    f.write(config)"
      ],
      "metadata": {
        "id": "cQcsie44G8mK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the config file\n",
        "\n",
        "%cat model_config.config"
      ],
      "metadata": {
        "id": "1tjjM_WwIA7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8) TESTING THE MODEL\n",
        "\n",
        "Export the model of training so the model can be used for the next step, which is OCR."
      ],
      "metadata": {
        "id": "z1yDIKdJYG_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Navigate to the object_detection folder\n",
        "%cd /content/models/research/object_detection"
      ],
      "metadata": {
        "id": "ZbwYG7z4OFUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export inference graph\n",
        "!python exporter_main_v2.py --trained_checkpoint_dir=/content/dataset/data/train_history --pipeline_config_path={pipeline_config_path} --output_directory /content/dataset/data/output/inference_graph"
      ],
      "metadata": {
        "id": "zRihm6hrJA1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the saved_model\n",
        "\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "# Output display size\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "# Path to the saved model\n",
        "PATH_TO_SAVED_MODEL = \"/content/dataset/output/inference_graph/saved_model\"\n",
        "print('Loading model...', end='')\n",
        "\n",
        "# Load saved model and build the detection function\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "print('Done!')\n",
        "\n",
        "# Loading the label_map\n",
        "# Specify the path to the label_map file\n",
        "category_index = label_map_util.create_category_index_from_labelmap(\"/content/dataset/data/label_map.pbtxt\", use_display_name=True)\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "# CHANGE THIS PATH IF YOU WANT TO TEST ANOTHER IMAGE\n",
        "image_path = \"/content/dataset/testing_images/receipt2363.jpg\"\n",
        "\n",
        "# Load the image into a numpy array\n",
        "image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "input_tensor = tf.convert_to_tensor(image_np)\n",
        "# The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "# Perform object detection on the input image\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "# All outputs are batches tensors.\n",
        "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "# We're only interested in the first num_detections.\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# Detection classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "# Create a copy of the image with detected boxes and labels\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "# Visualize boxes and labels on the image\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "    image_np_with_detections,\n",
        "    detections['detection_boxes'],\n",
        "    detections['detection_classes'],\n",
        "    detections['detection_scores'],\n",
        "    category_index,\n",
        "    use_normalized_coordinates=True,\n",
        "    max_boxes_to_draw=200,\n",
        "    min_score_thresh=.1,  # Adjust this value to set the minimum probability boxes to be classified as True\n",
        "    agnostic_mode=False\n",
        ")\n",
        "\n",
        "# Display the image with detected objects\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=IMAGE_SIZE, dpi=200)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(image_np_with_detections)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uvhdZDo2O30b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}